{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport torch \nimport torch.nn as nn\nfrom PIL import Image \nfrom pathlib import Path\nimport cv2\nimport torch.optim\nimport torchvision.transforms.functional as TF\nfrom torch.utils.data import Dataset, DataLoader, sampler\nimport time\nimport torchvision.models as models \nfrom torchinfo import summary\nfrom tqdm import tqdm\nimport glob\nfrom IPython.display import clear_output","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-03T16:46:41.717872Z","iopub.execute_input":"2023-08-03T16:46:41.718263Z","iopub.status.idle":"2023-08-03T16:46:45.183456Z","shell.execute_reply.started":"2023-08-03T16:46:41.718233Z","shell.execute_reply":"2023-08-03T16:46:45.182430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# READING DATASET","metadata":{}},{"cell_type":"code","source":"base_path=Path('/kaggle/input/38cloud-cloud-segmentation-in-satellite-images/38-Cloud_training/')\nred_dir =Path('/kaggle/input/38cloud-cloud-segmentation-in-satellite-images/38-Cloud_training/train_red/')\ngreen_dir =Path('/kaggle/input/38cloud-cloud-segmentation-in-satellite-images/38-Cloud_training/train_green/')\nblue_dir=Path('/kaggle/input/38cloud-cloud-segmentation-in-satellite-images/38-Cloud_training/train_blue/')\nnir_dir=Path('/kaggle/input/38cloud-cloud-segmentation-in-satellite-images/38-Cloud_training/train_nir/')\ngt_dir= Path('/kaggle/input/38cloud-cloud-segmentation-in-satellite-images/38-Cloud_training/train_gt/')","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:46:50.732792Z","iopub.execute_input":"2023-08-03T16:46:50.733973Z","iopub.status.idle":"2023-08-03T16:46:50.740468Z","shell.execute_reply.started":"2023-08-03T16:46:50.733924Z","shell.execute_reply":"2023-08-03T16:46:50.738877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CREATING CUSTOM PYTORCH DATACLASS","metadata":{}},{"cell_type":"code","source":"class CloudDataset(Dataset):\n    def __init__(self ,red_dir ,green_dir ,blue_dir ,nir_dir ,gt_dir ,pytorch=True):\n        super().__init__()\n        self.files =[self.combine_files(f ,green_dir ,blue_dir ,nir_dir ,gt_dir)  for f in red_dir.iterdir() if not f.is_dir()]\n        self.pytorch =pytorch\n        \n        \n    def combine_files (self ,r_file:Path ,green_dir ,blue_dir ,nir_dir ,gt_dir):\n        files ={'red' :r_file,\n               'green':green_dir/r_file.name.replace('red' ,'green'),\n               'blue' :blue_dir/r_file.name.replace('red','blue'),\n               'nir' :nir_dir/r_file.name.replace('red' ,'nir'),\n               'gt' :gt_dir/r_file.name.replace('red','gt')}\n        return files \n    \n    def __len__(self):\n        return len(self.files)\n    \n    def open_as_array(self, idx, invert=False, include_nir=False):\n\n        raw_rgb = np.stack([np.array(Image.open(self.files[idx]['red'])),\n                            np.array(Image.open(self.files[idx]['green'])),\n                            np.array(Image.open(self.files[idx]['blue'])),\n                           ], axis=2)\n    \n        if include_nir:\n            nir = np.expand_dims(np.array(Image.open(self.files[idx]['nir'])), 2)\n            raw_rgb = np.concatenate([raw_rgb, nir], axis=2)\n    \n        if invert:\n            raw_rgb = raw_rgb.transpose((2,0,1))\n            \n        # normalize\n        return (raw_rgb / np.iinfo(raw_rgb.dtype).max)\n    \n    def open_mask(self, idx, add_dims=False):\n        \n        raw_mask = np.array(Image.open(self.files[idx]['gt']))\n        raw_mask = np.where(raw_mask==255, 1, 0)\n        \n        return np.expand_dims(raw_mask, 0) if add_dims else raw_mask\n    \n    def __getitem__(self, idx):\n        \n        x = torch.tensor(self.open_as_array(idx, invert=self.pytorch, include_nir=True), dtype=torch.float32)\n        y = torch.tensor(self.open_mask(idx, add_dims=False), dtype=torch.torch.int64)\n        \n        return x, y\n    \n    def open_as_pil(self, idx):\n        \n        arr = 256*self.open_as_array(idx)\n        \n        return Image.fromarray(arr.astype(np.uint8), 'RGB')\n    \n    def __repr__(self):\n        s = 'Dataset class with {} files'.format(self.__len__())\n\n        return s","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:46:54.107230Z","iopub.execute_input":"2023-08-03T16:46:54.107588Z","iopub.status.idle":"2023-08-03T16:46:54.124419Z","shell.execute_reply.started":"2023-08-03T16:46:54.107557Z","shell.execute_reply":"2023-08-03T16:46:54.123398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data =CloudDataset(red_dir ,green_dir ,blue_dir ,nir_dir ,gt_dir)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:46:55.778790Z","iopub.execute_input":"2023-08-03T16:46:55.779466Z","iopub.status.idle":"2023-08-03T16:47:13.238682Z","shell.execute_reply.started":"2023-08-03T16:46:55.779433Z","shell.execute_reply":"2023-08-03T16:47:13.237616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(data)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:47:15.553205Z","iopub.execute_input":"2023-08-03T16:47:15.553564Z","iopub.status.idle":"2023-08-03T16:47:15.560874Z","shell.execute_reply.started":"2023-08-03T16:47:15.553535Z","shell.execute_reply":"2023-08-03T16:47:15.559966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(data)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:47:30.504730Z","iopub.execute_input":"2023-08-03T16:47:30.505113Z","iopub.status.idle":"2023-08-03T16:47:30.510658Z","shell.execute_reply.started":"2023-08-03T16:47:30.505080Z","shell.execute_reply":"2023-08-03T16:47:30.509532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting some stacked images ","metadata":{}},{"cell_type":"code","source":"x ,y =data[2000]\nx.shape ,y.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:47:35.517482Z","iopub.execute_input":"2023-08-03T16:47:35.517842Z","iopub.status.idle":"2023-08-03T16:47:35.668880Z","shell.execute_reply.started":"2023-08-03T16:47:35.517812Z","shell.execute_reply":"2023-08-03T16:47:35.667856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig ,ax =plt.subplots(1 ,2 ,figsize=(10,9))\nax[0].imshow(data.open_as_array(150))\nax[1].imshow(data.open_mask(150))\nax[0].set_title('image')\nax[1].set_title('mask')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:47:37.307464Z","iopub.execute_input":"2023-08-03T16:47:37.308408Z","iopub.status.idle":"2023-08-03T16:47:37.949973Z","shell.execute_reply.started":"2023-08-03T16:47:37.308364Z","shell.execute_reply":"2023-08-03T16:47:37.948912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id= torch.randint(0 ,len(data) ,(15,))\nid_list = id.tolist()\nfor ids in id_list:\n    plt.subplot(1, 2, 1)\n    plt.imshow(data.open_as_array(ids))\n    plt.subplot(1, 2, 2)\n    plt.imshow(data.open_mask(ids))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:47:40.206302Z","iopub.execute_input":"2023-08-03T16:47:40.206660Z","iopub.status.idle":"2023-08-03T16:47:47.030180Z","shell.execute_reply.started":"2023-08-03T16:47:40.206630Z","shell.execute_reply":"2023-08-03T16:47:47.029040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds  ,valid_ds = torch.utils.data.random_split(data, (7400, 1000))\ntrain_dl = DataLoader(train_ds, batch_size=12, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=12, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:47:52.936053Z","iopub.execute_input":"2023-08-03T16:47:52.936490Z","iopub.status.idle":"2023-08-03T16:47:52.946679Z","shell.execute_reply.started":"2023-08-03T16:47:52.936452Z","shell.execute_reply":"2023-08-03T16:47:52.945609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xb ,yb =next(iter(train_dl))","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:47:54.199664Z","iopub.execute_input":"2023-08-03T16:47:54.200148Z","iopub.status.idle":"2023-08-03T16:47:54.979625Z","shell.execute_reply.started":"2023-08-03T16:47:54.200109Z","shell.execute_reply":"2023-08-03T16:47:54.978679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xb.shape ,yb.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:48:06.684704Z","iopub.execute_input":"2023-08-03T16:48:06.685076Z","iopub.status.idle":"2023-08-03T16:48:06.691197Z","shell.execute_reply.started":"2023-08-03T16:48:06.685046Z","shell.execute_reply":"2023-08-03T16:48:06.690263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Jaccard function as a performance metric","metadata":{}},{"cell_type":"code","source":"def jaccard(img1, img2):\n    img1 = np.array(img1).astype(bool)\n    img2 = np.array(img2).astype(bool)\n    \n    U = np.logical_or(img1, img2)\n    I = np.logical_and(img1, img2)\n    \n    num = I.reshape(I.shape[0], -1).mean(axis=-1)\n    denum = U.reshape(U.shape[0], -1).mean(axis=-1)\n    \n    # to avoid division to 0\n    denum = np.where(denum == 0, -1, denum)\n    \n    measure = num / denum\n    measure = np.where(measure < 0, 0, measure)\n    return measure.mean(0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"markdown","source":"# VGGnet","metadata":{}},{"cell_type":"code","source":"VGG_types ={\n'VGG16' : [64 ,64 ,'M', 128 ,128 ,'M' ,256 ,256 ,256 ,'M', 512 ,512 ,512 ,'M' ,512 ,512 ,512 ,'M'],\n'VGG19' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n}\nclass VGG_net(nn.Module):\n    def __init__(self ,in_channels ,out_channels):\n        super(VGG_net ,self).__init__()\n        self.in_channels = in_channels\n        self.conv_layers = self.create_conv_layers(VGG_types['VGG19'])\n        #512x12x12. This should make the number of features after flattening equal to 512x12x12=73728, which matches the first fully connected layer's input size.\n        \n        self.fcs =nn.Sequential(\n            nn.Linear(512*12*12 ,4096),  \n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(4096 ,4096),\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            nn.Linear(4096 ,out_channels)\n            \n        )\n        \n    #Given an input tensor x, it passes the input through the convolutional layers, flattens the output, and then passes it through the fully connected layers.\n    def forward(self ,x):\n        x =self.conv_layers(x)\n        x = x.view(x.size(0), -1) #flattens the output tensor from the convolutional layers into a 1-dimensional tensor\n        x = self.fcs(x)\n        return x\n    \n    def create_conv_layers(self,architecture):\n        layers =[]\n        in_channels =self.in_channels\n        \n        for x in architecture :\n            if type(x) ==int:\n                out_channels = x\n                \n                layers +=[nn.Conv2d(in_channels ,out_channels ,kernel_size =(3,3) ,stride=(1,1) ,padding= (1,1)),\n                            nn.BatchNorm2d(x),\n                            nn.ReLU()]\n                in_channels =x\n                \n            elif x =='M':\n                layers += [nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))]\n                \n        return nn.Sequential(*layers)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:48:29.397641Z","iopub.execute_input":"2023-08-03T16:48:29.398121Z","iopub.status.idle":"2023-08-03T16:48:29.421385Z","shell.execute_reply.started":"2023-08-03T16:48:29.398077Z","shell.execute_reply":"2023-08-03T16:48:29.419706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n#VGG_NET = VGG_net(4 ,2).to(device)\nVGG_NET = VGG_net(in_channels=4 ,out_channels=2)\nx =torch.randn(1 ,4 ,384 ,384)\nprint(VGG_NET(x).shape)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:48:43.013525Z","iopub.execute_input":"2023-08-03T16:48:43.013914Z","iopub.status.idle":"2023-08-03T16:48:47.502721Z","shell.execute_reply.started":"2023-08-03T16:48:43.013867Z","shell.execute_reply":"2023-08-03T16:48:47.501666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import hiddenlayer as hl\n\n#transforms = [ hl.transforms.Prune('Constant') ] # Removes Constant nodes from graph.\n\n#graph = hl.build_graph(VGG_NET, torch.zeros([12, 4, 384, 384]), transforms=transforms)\n#graph.theme = hl.graph.THEMES['blue'].copy()\n#graph.save('rnn_hiddenlayer', format='png')","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:45:43.154544Z","iopub.status.idle":"2023-08-03T16:45:43.154955Z","shell.execute_reply.started":"2023-08-03T16:45:43.154740Z","shell.execute_reply":"2023-08-03T16:45:43.154759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VGG_NET","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:48:52.375601Z","iopub.execute_input":"2023-08-03T16:48:52.375999Z","iopub.status.idle":"2023-08-03T16:48:52.384294Z","shell.execute_reply.started":"2023-08-03T16:48:52.375966Z","shell.execute_reply":"2023-08-03T16:48:52.382401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(VGG_NET, input_size=(8, 4, 384, 384))","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:48:58.614274Z","iopub.execute_input":"2023-08-03T16:48:58.614623Z","iopub.status.idle":"2023-08-03T16:49:06.499661Z","shell.execute_reply.started":"2023-08-03T16:48:58.614595Z","shell.execute_reply":"2023-08-03T16:49:06.498725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#testing one pass\nxb, yb = next(iter(train_dl))\nxb.shape, yb.shape\n\npred = VGG_NET(xb)\npred.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:45:43.158945Z","iopub.status.idle":"2023-08-03T16:45:43.159442Z","shell.execute_reply.started":"2023-08-03T16:45:43.159123Z","shell.execute_reply":"2023-08-03T16:45:43.159141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UNET","metadata":{}},{"cell_type":"code","source":"from torch import nn\nclass UNET(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n\n        self.conv1 = self.contract_block(in_channels, 32, 7, 3)\n        self.conv2 = self.contract_block(32, 64, 3, 1)\n        self.conv3 = self.contract_block(64, 128, 3, 1)\n\n        self.upconv3 = self.expand_block(128, 64, 3, 1)\n        self.upconv2 = self.expand_block(64*2, 32, 3, 1)\n        self.upconv1 = self.expand_block(32*2, out_channels, 3, 1)\n\n    def __call__(self, x):\n\n        # downsampling part\n        conv1 = self.conv1(x)\n        conv2 = self.conv2(conv1)\n        conv3 = self.conv3(conv2)\n\n        upconv3 = self.upconv3(conv3)\n\n        upconv2 = self.upconv2(torch.cat([upconv3, conv2], 1))\n        upconv1 = self.upconv1(torch.cat([upconv2, conv1], 1))\n\n        return upconv1\n\n    def contract_block(self, in_channels, out_channels, kernel_size, padding):\n\n        contract = nn.Sequential(\n            torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n            torch.nn.BatchNorm2d(out_channels),\n            torch.nn.ReLU(),\n            torch.nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n            torch.nn.BatchNorm2d(out_channels),\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n                                 )\n\n        return contract\n\n    def expand_block(self, in_channels, out_channels, kernel_size, padding):\n\n        expand = nn.Sequential(torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n                            torch.nn.BatchNorm2d(out_channels),\n                            torch.nn.ReLU(),\n                            torch.nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),\n                            torch.nn.BatchNorm2d(out_channels),\n                            torch.nn.ReLU(),\n                            torch.nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1) \n                            )\n        return expand","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:49:13.526019Z","iopub.execute_input":"2023-08-03T16:49:13.526390Z","iopub.status.idle":"2023-08-03T16:49:13.541401Z","shell.execute_reply.started":"2023-08-03T16:49:13.526359Z","shell.execute_reply":"2023-08-03T16:49:13.540201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unet_model =UNET(4 , 2).cuda()","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:49:15.207586Z","iopub.execute_input":"2023-08-03T16:49:15.207995Z","iopub.status.idle":"2023-08-03T16:49:15.229043Z","shell.execute_reply.started":"2023-08-03T16:49:15.207963Z","shell.execute_reply":"2023-08-03T16:49:15.228059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary(unet_model, input_size=(8, 4, 384, 384))","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:50:35.468582Z","iopub.execute_input":"2023-08-03T16:50:35.469009Z","iopub.status.idle":"2023-08-03T16:50:35.565847Z","shell.execute_reply.started":"2023-08-03T16:50:35.468976Z","shell.execute_reply":"2023-08-03T16:50:35.564890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xb, yb = next(iter(train_dl))\nxb.shape, yb.shape\npred = unet_model(xb)\npred.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:49:18.880814Z","iopub.execute_input":"2023-08-03T16:49:18.881229Z","iopub.status.idle":"2023-08-03T16:49:19.982336Z","shell.execute_reply.started":"2023-08-03T16:49:18.881193Z","shell.execute_reply":"2023-08-03T16:49:19.980792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn =nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(unet_model.parameters() , lr =0.001)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:50:42.890584Z","iopub.execute_input":"2023-08-03T16:50:42.890963Z","iopub.status.idle":"2023-08-03T16:50:42.896371Z","shell.execute_reply.started":"2023-08-03T16:50:42.890928Z","shell.execute_reply":"2023-08-03T16:50:42.895431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, train_dl, valid_dl, loss_fn, optimizer, acc_fn, epochs=12):\n    start = time.time()\n    model.cuda()\n\n    train_loss, valid_loss = [], []\n\n    best_acc = 0.0\n\n    for epoch in range(epochs):\n        print('Epoch {}/{}'.format(epoch, epochs - 1))\n        print('-')\n\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                model.train(True)  # Set trainind mode = true\n                dataloader = train_dl\n            else:\n                model.train(False)  # Set model to evaluate mode\n                dataloader = valid_dl\n\n            running_loss = 0.0\n            running_acc = 0.0\n\n            step = 0\n\n            # iterate over data\n            for x, y in dataloader:\n                x = x.cuda()\n                y = y.cuda()\n                step += 1\n\n                # forward pass\n                if phase == 'train':\n                    # zero the gradients\n                    optimizer.zero_grad()\n                    outputs = model(x)\n                    loss = loss_fn(outputs, y)\n\n                    # the backward pass frees the graph memory, so there is no \n                    # need for torch.no_grad in this training pass\n                    loss.backward()\n                    optimizer.step()\n                    # scheduler.step()\n\n                else:\n                    with torch.no_grad():\n                        outputs = model(x)\n                        loss = loss_fn(outputs, y.long())\n\n                # stats - whatever is the phase\n                acc = acc_fn(outputs, y)\n\n                running_acc  += acc*dataloader.batch_size\n                running_loss += loss*dataloader.batch_size \n\n                if step % 100 == 0:\n                    # clear_output(wait=True)\n                    print('Current step: {}  Loss: {}  Acc: {}  AllocMem (Mb): {}'.format(step, loss, acc, torch.cuda.memory_allocated()/1024/1024))\n                    # print(torch.cuda.memory_summary())\n\n            epoch_loss = running_loss / len(dataloader.dataset)\n            epoch_acc = running_acc / len(dataloader.dataset)\n\n            clear_output(wait=True)\n            print('Epoch {}/{}'.format(epoch, epochs - 1))\n            print('-' * 10)\n            print('{} Loss: {:.4f} Acc: {}'.format(phase, epoch_loss, epoch_acc))\n            print('-' * 10)\n\n            train_loss.append(epoch_loss) if phase=='train' else valid_loss.append(epoch_loss)\n\n    time_elapsed = time.time() - start\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n    \n    return train_loss, valid_loss    \n\ndef acc_metric(predb, yb):\n    return (predb.argmax(dim=1) == yb.cuda()).float().mean()","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:52:29.526152Z","iopub.execute_input":"2023-08-03T16:52:29.526549Z","iopub.status.idle":"2023-08-03T16:52:29.543141Z","shell.execute_reply.started":"2023-08-03T16:52:29.526518Z","shell.execute_reply":"2023-08-03T16:52:29.542007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.cuda.amp as amp\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\noptimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)\ngrad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\ncriterion = nn.CrossEntropyLoss()\nglobal_step = 0\n\ndef train_segmentation_model(model, train_loader, val_loader, epochs, optimizer, criterion,\n                             scheduler, gradient_clipping, device, amp=False):\n    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n    global_step = 0\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        with tqdm(total=len(train_loader.dataset), desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n            for batch in train_loader:\n                images, true_masks = batch['image'], batch['mask']\n\n                assert images.shape[1] == model.n_channels, \\\n                    f'Network has been defined with {model.n_channels} input channels, ' \\\n                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n                    'the images are loaded correctly.'\n\n                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n                true_masks = true_masks.to(device=device, dtype=torch.long)\n\n                with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n                    masks_pred = model(images)\n                    if model.n_classes == 1:\n                        loss = criterion(masks_pred.squeeze(1), true_masks.float())\n                        loss += dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)\n                    else:\n                        loss = criterion(masks_pred, true_masks)\n                        loss += dice_loss(\n                            F.softmax(masks_pred, dim=1).float(),\n                            F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float(),\n                            multiclass=True\n                        )\n\n                optimizer.zero_grad(set_to_none=True)\n                grad_scaler.scale(loss).backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n                grad_scaler.step(optimizer)\n                grad_scaler.update()\n\n                pbar.update(images.shape[0])\n                global_step += 1\n\n                # Evaluation round (if needed)\n                division_step = (len(train_loader.dataset) // (5 * train_loader.batch_size))\n                if division_step > 0 and global_step % division_step == 0:\n                    val_score = evaluate(model, val_loader, device, amp)\n                    scheduler.step(val_score)\n\n# Define other necessary functions (evaluate, dice_loss, etc.) before calling this function.\n\n# Usage example:\n# train_segmentation_model(model, train_loader, val_loader, epochs, optimizer, criterion,\n#                          scheduler, gradient_clipping, device, amp=False)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss ,valid_loss = train(unet_model ,train_dl ,valid_dl ,loss_fn ,optimizer ,acc_matric ,epochs =12)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:52:31.096274Z","iopub.execute_input":"2023-08-03T16:52:31.096625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save the model","metadata":{}},{"cell_type":"code","source":"torch.save(UNet, '/kaggle/working/trained_model')","metadata":{},"execution_count":null,"outputs":[]}]}